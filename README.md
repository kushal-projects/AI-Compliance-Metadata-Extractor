
# ğŸ¦ AI Compliance Metadata Extractor

**AI-powered tool for extracting structured metadata from compliance policy documents (PDF or TXT) using the power of LLMs â€” no API needed!**

![Demo Screenshot](/Demo.png)

## ğŸ”— App Link

<p style="font-size: 14px;">
ğŸš€ Check out the live demo on <strong>Hugging Face Spaces</strong>:<br>
ğŸ‘‰ <a href="https://huggingface.co/spaces/kushh108/compliance-metadata-extractor" target="_blank">
AI Powered Compliance Metadata Extractor
</a>
</p>

---

## ğŸ“Œ Scope

Organizations often have hundreds of compliance documents spread across teams and formats. Manually tracking key metadata like **policy names**, **owners**, and **last updated dates** is inefficient and error-prone.

> This tool solves that by **automatically extracting compliance metadata using a open-source large language model - TinyLlama**, enabling fast policy cataloging, audits, and reporting.

---
## ğŸ¯ Why This Matters

âœ… **Time-saving**: Automates a manual, repetitive task  
âœ… **Risk-reduction**: Improves compliance audit readiness  
âœ… **Privacy-focused**: No need to send data to third-party APIs  
âœ… **Deployable**: Ready for integration in enterprise workflows  

---

## ğŸš€ What This Does

- ğŸ—ƒï¸ **Takes PDF or plain text** files of compliance policies
- ğŸ” **Extracts metadata** fields like: Policy name, author, version, dates, department, contact, Table of contents
- ğŸ§  Uses a lightweight **open-source LLM** (no API keys)
- ğŸ›ï¸ User-friendly **Gradio App Interface**
- ğŸ“„ Outputs results in structured JSON and .txt formats

---


## ğŸ›  Tech Stack

| Tool | Role |
|------|------|
| ![Python](https://img.shields.io/badge/-Python-3776AB?style=flat&logo=python&logoColor=white) | ğŸ Core programming language |
| <img src="https://smol.p1x.in/img/tinyllama.gif" alt="TinyLlama" width="70"/> <br> **TinyLlama** | ğŸ¤– Large Language Model |
| ![Pdfplumber](https://img.shields.io/badge/-pdfplumber-343541?style=flat&logo=adobe-acrobat-reader&logoColor=EC1C24) | ğŸ§¾ PDF text extraction |
| ![Gradio](https://img.shields.io/badge/-Gradio-FF4C4C?style=flat&logo=gradio&logoColor=white) | ğŸ› User interface for file input/output |
| ![Hugging Face Transformers](https://img.shields.io/badge/-Transformers-FFD21F?style=flat&logo=huggingface&logoColor=black) | ğŸ“¦ Model loading and tokenizer support |
| ![PyTorch](https://img.shields.io/badge/-PyTorch-EE4C2C?style=flat&logo=pytorch&logoColor=white) | ğŸ§  LLM backend for inference |


---
## ğŸ“¦ How to Run Locally

1. **Clone the repository**
2. **Install dependencies**
3. **Run the app**
4. Open your browser at [http://127.0.0.1:7860](http://127.0.0.1:7860)
5. (Optional) To get a public link, set `share=True` in `app.py` in the `demo.launch()` line

## Results
| ğŸ“ Compliance Document (Input) | ğŸ“¤ Extracted Metadata (Output) |
|:-----------------------------:|:------------------------------:|
| <img src="Images/DOC_pg1.png" alt="Input Doc" width="200"/> | <img src="Images/Result.png" alt="Output Metadata" width="600"/> |
| <img src="Images/DOC_pg2.png" alt="Input Doc" width="200"/> |

**You may try it live using the app link above.**  
**Processing time may vary depending on the size of the document.**


## âš ï¸ Limitations

- âŒ The current setup struggles with **very large PDF or text files**, potentially leading to memory overload or timeouts errors.
- âŒ Model may misclassify or omit metadata in complex or unstructured documents.
- ğŸ§  TinyLlama is a lightweight model optimized for simplicity and speedâ€”not for deep semantic understanding.
- ğŸ“„ Currently supports only **English-language** PDFs.
- ğŸ›  Metadata fields are hardcoded; adding new types requires manual updates to the extraction pipeline.
- ğŸ” Sensitive keys or tokens must be manually redacted before pushing to public platforms.

---

## ğŸš€ Scope for Improvement

### ğŸ§  Model Upgrades
- âš¡ Integrate **powerful open-source LLMs** such as:
  - ğŸ”¹ **Mistral-7B** â€“ A robust and fast model for complex text understanding.
  - ğŸ”¹ **Mixtral** â€“ A sparse mixture-of-experts model great for multitask comprehension.
  - ğŸ”¹ **Phi-2** by Microsoft â€“ Small yet surprisingly accurate for task-specific compliance QA.

### ğŸš« Why Not Mistral-7B?

**Mistral-7B** is a **robust** and **high-performing open-weight model** well-suited for complex text understanding tasks. However, it comes with **significant system requirements**:

- ğŸ§  **Requires 16â€“32 GB of GPU VRAM**  
- ğŸ’» **Needs â‰¥48 GB of system RAM**  
- âš™ï¸ Optimized for high-end GPUs like **NVIDIA A100**, **RTX 3090**, or **RTX 4090**

âš ï¸ **Due to limited hardware availability and system resource constraints**, implementing Mistral-7B was not feasible for this project.

âœ… Instead, the **TinyLlama** model was selected as a **lightweight**, efficient, and deployable alternative for resource-constrained environments.

### ğŸŒ Feature Enhancements
- ğŸŒ Add **multilingual support** for international compliance policies.
- ğŸ“Š Build an **interactive dashboard** to visualize extracted metadata and trends.
- ğŸ¤– Use **retrieval-augmented generation (RAG)** for context-aware metadata extraction.
- ğŸ”§ **Modularize the architecture** to easily switch between LLMs and adapt pipelines by domain.
- â˜ï¸ Enable **cloud deployment** (e.g., Hugging Face Hub + Inference API) for scalable, on-demand usage.


---

## ğŸ‘¨â€ğŸ’» Author

**Kushal Tiwari**  
**Building AI with Language Models & Automation:** Passionate about real-world AI/ML and data science applications

---

## ğŸ“¬ Contact

- ğŸ“§ **Email**: [23f3000514@ds.study.iitm.ac.in](mailto:23f3000514@ds.study.iitm.ac.in)
- ğŸ’¼ **LinkedIn**: [linkedin.com/in/yourprofile](https://www.linkedin.com/in/yourprofile)
- ğŸŒ **Portfolio**: [yourwebsite.dev](https://yourwebsite.dev)

---


